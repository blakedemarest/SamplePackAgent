# Architecture Overview

The Sample Pack Agent operates using a **Perceive -> Plan -> Act -> Evaluate** loop, designed to automate the creation of sound effect libraries from natural language briefs. The architecture is modular, with distinct components handling each stage, leveraging external Large Language Models (LLMs) and AI audio generation, combined with audio processing tools. This structure is intended to be extensible and adaptable as AI capabilities evolve.

## Current Architecture (Single Brief Processing)

The current implementation provides a foundational pipeline for processing a single SFX brief and generating multiple variations of that sound, primarily by adjusting a key parameter ('prompt_influence') during the generation phase.

The loop works as follows for a single brief:

1.  **Perceive (Input Handling):**
    *   Receives a single text brief from the user (CLI arguments or interactive prompt).
    *   Loads and validates the core configuration (`configs/sfx_agent.yml`).
    *   Handled by `sfx_agent/input_handler.py` and `sfx_agent/config.py`.

2.  **Plan (Decomposition - Basic):**
    *   The single free-form brief is sent to a local LLM (Gemma via Ollama) with instructions to extract structured parameters (source, timbre, dynamics, duration, pitch, space, analogy, influence).
    *   Handled by `sfx_agent/decomposer.py`, which calls the `ollama eval` subprocess, expecting JSON output.

3.  **Act (Generation & Processing Loop - Parameter Variation):**
    *   The agent iterates through a predefined list of `batch_influences` from the configuration.
    *   For *each* influence value in the list:
        *   **Compose Prompt:** The structured parameters (incorporating the current influence value and duration) are formatted into a text prompt string using a template.
            *   Handled by `sfx_agent/composer.py`.
        *   **Generate Audio:** The prompt is sent to the ElevenLabs API along with parameters like duration and influence. The raw audio is saved to a temporary file.
            *   Handled by `sfx_agent/generator.py`.
        *   **Post-Process:** The raw audio file is loaded, audio metrics (LUFS, peak) are measured, loudness normalization to a target LUFS is applied, and the processed audio is saved to the final output directory.
            *   Handled by `sfx_agent/post_processor.py`, using `pydub`, `pyloudnorm`, and `ffmpeg`.

4.  **Evaluate (Store Results):**
    *   Metadata and processing metrics for each successful SFX variation are collected.
    *   This data is appended to a YAML library file (`prompt_library.yml`) for record-keeping.
    *   Handled by `sfx_agent/library.py`.

The `sfx_agent/runner.py` module orchestrates this sequence, manages the loop over batch influences, and handles basic error logging for individual variations.

**Core Tools Used (Current):** `ollama`, `elevenlabs` SDK, `pydub`, `pyloudnorm`, `ffmpeg`, `ruamel.yaml`.

## Future Architecture (Bulk Generation & Iterative Refinement)

The future architecture is designed to tackle complex "bulk" briefs requesting large quantities of diverse sounds across multiple categories. It also incorporates an iterative feedback loop driven by AI analysis of audio metrics to refine the generation process. This represents a significant step towards a more autonomous and powerful sound design agent, aligned with a vision of increasingly capable AI-driven workflows.

The planned architecture includes:

1.  **Enhanced Planning (Hierarchical Decomposition & Diverse Prompt Generation):**
    *   The **Decomposition/Planning** stage will be expanded to handle complex bulk briefs (e.g., specifying categories, counts, overall themes).
    *   The LLM will be used to break down the complex brief into a structured *plan* for the entire sample pack.
    *   This involves generating not just parameters for a single sound, but a series of distinct prompt *templates* or specific prompt *ideas* for each category required.
    *   Further LLM interaction or programmatic logic will expand and mutate these seed ideas into the target number of unique prompt variations needed for the pack, ensuring diversity and adherence to the brief's constraints.

2.  **Refined Act (Job Execution):**
    *   The agent will process the list of planned, unique SFX "jobs" (each corresponding to a specific prompt/parameter set) generated by the planning stage.
    *   The core generation and post-processing steps remain, but they are now executed for a multitude of distinct sonic goals, not just variations of one idea.
    *   `batch_influences` might still be applied per unique prompt to add micro-variations, but the primary source of pack diversity comes from the planned prompts.

3.  **Integrated Evaluate & AI Critique Loop:**
    *   After audio generation and processing, metrics (LUFS, peak, potentially others) are calculated.
    *   These metrics, along with the original prompt and potentially other relevant context (like the brief or previous feedback), are fed back to the LLM via the `feedback.py` module.
    *   The LLM analyzes the metrics and provides structured suggestions on how to modify the *prompt* or parameters to improve the resulting audio quality or characteristics (e.g., reduce clipping, adjust perceived brightness).
    *   The `runner` or a dedicated control module will use this structured feedback to modify the parameters or prompt templates for *future* generations within the same bulk job or category, creating an iterative refinement cycle aiming to improve the overall quality and consistency of the output over time.

4.  **Resource Management:** Implement robust handling for large generation queues, including batching, potential parallelization, and managing external API rate limits and costs effectively.

5.  **Metadata & Organization:** Metadata (including the detailed processing results and potentially LLM feedback summaries) will be systematically stored, likely evolving the `prompt_library.yml` structure to handle hierarchical data for bulk packs. Integration with `mutagen` will embed key metadata directly into audio files. This is essential for supporting a usable library interface.

6.  **User Interface:** Develop a graphical user interface (using PyQt5 initially, or a web framework) to provide a user-friendly way to input briefs, configure the agent, monitor progress, review generated sounds and their metadata, and interact with the critique feedback.

## Changes Required to Reach the Future Vision

Achieving the future architecture requires substantial development effort, primarily focused on enhancing the AI interaction and the orchestration logic to manage complexity and integrate feedback.

Key areas requiring change:

1.  **`sfx_agent/input_handler.py` (Potential Enhancements):** May need updates to parse more complex input formats for bulk briefs, or this parsing complexity might shift entirely to the decomposition layer.

2.  **`sfx_agent/decomposer.py` (Significant R&D & Rework or Split):**
    *   Requires new LLM prompting strategies and parsing logic capable of understanding complex, multi-part bulk briefs.
    *   Must incorporate logic to generate multiple *distinct* prompt templates or prompt *ideas* based on categories and creative goals derived from the brief.
    *   Needs implementation of template expansion and mutation logic (potentially involving further LLM calls for variations/synonyms) to scale the number of unique prompts per category.
    *   This module's complexity might warrant splitting into separate "Decomposition" (initial brief parse) and "Planning" (template/prompt generation) modules. This area is a core R&D focus, exploring the limits of LLM capabilities for complex creative planning.

3.  **`sfx_agent/runner.py` (Major Rework):**
    *   Must be redesigned to accept and manage a list of distinct SFX generation "jobs" (each defined by a unique prompt/parameters) from the planning stage.
    *   Implement the logic for the iterative **Evaluate & Critique** loop: calling `feedback.py` with appropriate data and using the returned structured feedback to potentially modify parameters or prompts for subsequent jobs in the queue.
    *   Incorporate resource management logic (batching, handling API responses, potential parallel execution).
    *   Needs enhanced error handling and retry logic, especially around external API calls (Ollama, ElevenLabs).

4.  **`sfx_agent/feedback.py` (Full Implementation & R&D):**
    *   Requires development of sophisticated LLM prompts and parsing to analyze audio metrics (from `post_processor`) in the context of the input prompt, and generate structured, actionable text suggestions for prompt modification aimed at changing specific audio characteristics. This is another significant AI R&D challenge.

5.  **`sfx_agent/library.py` (Structure Update & Integration):**
    *   The internal data structure (YAML schema) needs to be updated to better organize results from large, multi-category bulk jobs (e.g., nested under job IDs or categories).
    *   Must be robust against concurrent access if parallel processing is introduced.
    *   Needs tight integration with the UI layer to allow browsing and querying the stored metadata.

6.  **`sfx_agent/post_processor.py` (Minor Enhancements):** May require calculation of additional audio metrics if deemed necessary for the AI critique process.

7.  **`sfx_agent/generator.py` (Potential Integration):** Integration with `mutagen` for embedding metadata might be best placed here after file saving, or potentially in the post-processing step.

8.  **User Interface (`PyQt5` or Web):**
    *   Requires building a separate application layer that provides user input forms, visual progress indicators for bulk jobs, a browsable and searchable view of the generated library, and display/interaction elements for the AI critique feedback.

These changes represent the core work needed to evolve the Sample Pack Agent into a powerful tool capable of executing complex sound design briefs at scale, driven by an iterative, AI-assisted creative process. It's an ambitious research and development endeavor, pushing the boundaries of how AI can be integrated into creative audio workflows.